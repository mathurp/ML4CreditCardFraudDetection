{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catching Criminals with Math\n",
    "### Identification of fraudulent credit card transactions using statistical and machine learning models\n",
    "#### March 8th, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors: Angad S. Kalra, Pulkit Mathur and Shuang Di\n",
    "#### Collaborators: Shobhit Jain and Adam Rahman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "##### Problem Statement: \n",
    "* Every year billions of dollars are lost worldwide due to credit card fraud, which forces financial institutions to continuously improve their fraud detection systems. In recent years, several studies have proposed the use of machine learning and data mining techniques to address this problem.\n",
    "* When constructing a credit card fraud detection model, it is very important to extract the right features from the transactional data. However, this has not been addressed much in previous studies.\n",
    "* Moreover, most studies used some sort of misclassification measure to evaluate the different solutions, and do not take into account the actual financial costs associated with the fraud detection process.\n",
    "* In this project, we expand the existing work on credit card fraud dection by performing different feature engineering techniques, machine learning algorithms, and model evaluation methods with actual financial cost taken into consideration.\n",
    "\n",
    "##### Primary Questions: \n",
    "1. What are the characteristics of fraudulent transactions?\n",
    "2. Is there a statistical/ML model that can accurately detect fraud through retrospective data?\n",
    "\n",
    "##### Dataset description:\n",
    "* The dataset is generated by simulator called PaySim.\n",
    "* PaySim simulator:\n",
    "    * Generates a synthetic dataset from aggregated private dataset to resemble normal transaction behavior.\n",
    "    * Combination of statistical and social network analysis.\n",
    "    * Malicious transactions are later injected to the synthetic dataset.\n",
    "    * The dataset contains 6,372,620 transactions simulated to resemble a month of data.\n",
    "    * Each transaction is described using 10 featues.\n",
    "\n",
    "##### Attributes description:\n",
    "* CASH-IN - Process of increasing the amount available for purchases (e.g. paying your credit card bill)\n",
    "* CASH-OUT - Opposite of CASH-IN, it means to withdraw cash which decreases the amount available\n",
    "* DEBIT - Is similar process to CASH-OUT and involves sending the money to other account (e.g. preauthorized debit)\n",
    "* BILL-PAYMENT - Paying online bills (e.g. hydro)\n",
    "* PURCHASE - Process of sending money to another user for goods or services\n",
    "* Time_Stamp - Transactions recorded on hourly basis (~31 days of simulation)\n",
    "* Transaction_Type - CASH-IN, CASH-OUT, DEBIT, BILL-PAYMENT and PURCHASE \n",
    "* Amount - Amount of transaction in local currency\n",
    "* Client_Id - ID of the client who initiated the transaction (credit card holder)\n",
    "* Client_Old_Balance - Balance before transaction\n",
    "* Cleint_New_Balance - Balance after transaction\n",
    "* Merchant_Id - ID of the merchant\n",
    "* Merchant_Old -_Balance - Balance before transaction\n",
    "* Merchant_New_Balance - Balance after transaction\n",
    "* Is_Fraud - Fraudulent transaction flag (target variable)\n",
    "* Is_Flagged_Fraud - Any transaction amount  > 200,000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Methods\n",
    "\n",
    "#### Data Collection\n",
    "In this project, we work on a synthetic dataset generated using the simulator called PaySim. The data is given to us in a CSV. There are approx. 6.3 million transactions from approx. 950K clients.\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "##### ML Models\n",
    "1. Transform Transaction_Type column into a one-hot encoding using Pandas get_dummies() function.\n",
    "2. Remove these columns: 'Time_Stamp', 'Merchant_Id', 'Merchant_Old_Balance', 'Merchant_New_Balance', 'Is_Flagged_Fraud'. \n",
    "3. Create feature '%_of_balance' by performing transaction-wise division: Amount/Client_Old_Balance.  \n",
    "4. Combine Client_Old_Balance and Client_New_Balance into one feature by taking the difference in values. Remove Client_Old_Balance and Client_New_Balance Columns.\n",
    "\n",
    "##### Time-Series Models\n",
    "To capture the time series information associated with a transaction, we will model the time of the transaction as a periodic variable, using the von Mises distribution (periodic normal distribution).\n",
    "\n",
    "#### Data Preprocessing\n",
    "1. Standardize all numerical columns by subtracting each value in a column from the mean and dividing by the standard deviation. \n",
    "\n",
    "#### Undersample Majority Class\n",
    "1. Find indices for non-fraud transactions and indices for fraud transactions. \n",
    "2. Randomly select n non-fraud indices where n equals number of fraud transactions. \n",
    "3. Concatenate non-fraud indices and fraud indices and select those transactions as your new dataset. \n",
    "\n",
    "#### Oversample Minority Class\n",
    "1. TODO SHUANG\n",
    "\n",
    "#### Model Training\n",
    "1. Split the dataset into a training and test set using an 80/20 split. \n",
    "2. Train the follow models on the training set, using cross-validation for selection of hyper parameters when appropriate: \n",
    "    * Logistic Regression\n",
    "    * SVM with RBF kernel\n",
    "    * Random forest \n",
    "    * K Nearest Neighbours\n",
    "    * LGBM Classifier\n",
    "\n",
    "#### Model Evaluation \n",
    "Calculate the following for each of the models above: \n",
    "* Accuracy\n",
    "* AUC score\n",
    "* F1 score\n",
    "\n",
    "#### Model Interpretation\n",
    "* TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Exploratory Data Analysis:\n",
    "Exploratory Data Analysis has been carried out to answer the following questions:\n",
    "\n",
    "1. What is the ratio of non-fraud transactions to fraud transactions?\n",
    "2. What is the average number of trans. per client?\n",
    "3. What are the counts for different transactions types for fraud transactions? Use histogram.\n",
    "4. How many unique merchant IDs are there? Are there any common merchants for fraud transactions?\n",
    "\n",
    "By exploring the dataset, we've come up with insights that can help with data preprocessing, feature engineering, model selection, and model evaluation.\n",
    "\n",
    "* First, we know that the data is severely unbalanced because the number of transactions that are fraud is 0.3% of the dataset (approx. 18000). Thus, we explored different training techniques such as under-sampling and over-sampling, so we can have an equal number of positive and negative cases.\n",
    "* Also, we notice that the proportion of clients with more than 1 transaction recorded is very small (around 1.5%); thus it is not feasible to fit time series model on each client's transaction data.\n",
    "* In addition, we also know that all the fraud transactions were one of two types: Cash-Out and Purchase. Thus we might explore how filtering incoming transactions can increase prediction accuracy.\n",
    "\n",
    "(TODO...)\n",
    "\n",
    "#### Model Evaluation:\n",
    "\n",
    "| Model | Accuracy | AUC | F1 Score |\n",
    "| --- | --- | --- | --- |\n",
    "| Logistic Regression | 0.9607430453879942 | 0.9946000805218244 | 0.9604353038826893 |\n",
    "| SVM with RBF kernel | 0.9652269399707174 | 0.9949346111874423 | 0.9648343512863226 |\n",
    "| Random forest | 0.9989019033674963 | 0.9995288267461078 | 0.9989000916590285 |\n",
    "| K Nearest Neighbours (k=5) | 0.9808748169838946 | 0.993928021393885 | 0.9810224280395896 |\n",
    "| LGBM Classifier | 0.9990894509763931 | 0.9998040363109248 | 0.9990882827791965 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "(TODO...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "(TODO...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
